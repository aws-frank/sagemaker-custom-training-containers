{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Custom Framework Container</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to build and use a simple custom Docker container for training with Amazon SageMaker that leverages on the sagemaker-containers library to define framework containers; framework containers can load user code dynamically, either from Amazon S3 or by pointing a GitHub repository. Reference documentation is available at https://github.com/aws/sagemaker-containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining some variables like the current execution role, the ECR repository that we are going to use for pushing the custom Docker container and a default Amazon S3 bucket to be used by Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825935527263\n",
      "eu-west-1\n",
      "arn:aws:iam::825935527263:role/service-role/AmazonSageMaker-ExecutionRole-endtoendml\n",
      "sagemaker-eu-west-1-825935527263\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_namespace = 'gianpo-ecr/'\n",
    "prefix = 'framework-container'\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = get_execution_role()\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the Dockerfile which defines the statements for building our custom framework container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mFROM\u001b[39;49;00m\u001b[33m ubuntu:16.04\u001b[39;49;00m\n",
      "\n",
      "LABEL \u001b[31mmaintainer\u001b[39;49;00m=\u001b[33m\"Amazon AI\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Defining some variables used at build time to install Python3\u001b[39;49;00m\n",
      "ARG \u001b[31mPYTHON\u001b[39;49;00m=python3\n",
      "ARG \u001b[31mPYTHON_PIP\u001b[39;49;00m=python3-pip\n",
      "ARG \u001b[31mPIP\u001b[39;49;00m=pip3\n",
      "ARG \u001b[31mPYTHON_VERSION\u001b[39;49;00m=\u001b[34m3\u001b[39;49;00m.6.6\n",
      "\n",
      "\u001b[37m# Install some handful libraries like curl, wget, git, build-essential, zlib\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m apt-get update && apt-get install -y --no-install-recommends software-properties-common && \u001b[33m\\\u001b[39;49;00m\n",
      "    add-apt-repository ppa:deadsnakes/ppa -y && \u001b[33m\\\u001b[39;49;00m\n",
      "    apt-get update && apt-get install -y --no-install-recommends \u001b[33m\\\u001b[39;49;00m\n",
      "        build-essential \u001b[33m\\\u001b[39;49;00m\n",
      "        ca-certificates \u001b[33m\\\u001b[39;49;00m\n",
      "        curl \u001b[33m\\\u001b[39;49;00m\n",
      "        wget \u001b[33m\\\u001b[39;49;00m\n",
      "        git \u001b[33m\\\u001b[39;49;00m\n",
      "        libopencv-dev \u001b[33m\\\u001b[39;49;00m\n",
      "        openssh-client \u001b[33m\\\u001b[39;49;00m\n",
      "        openssh-server \u001b[33m\\\u001b[39;49;00m\n",
      "        vim \u001b[33m\\\u001b[39;49;00m\n",
      "        zlib1g-dev && \u001b[33m\\\u001b[39;49;00m\n",
      "    rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "\u001b[37m# Installing Python3\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m wget https://www.python.org/ftp/python/\u001b[31m$PYTHON_VERSION\u001b[39;49;00m/Python-\u001b[31m$PYTHON_VERSION\u001b[39;49;00m.tgz && \u001b[33m\\\u001b[39;49;00m\n",
      "        tar -xvf Python-\u001b[31m$PYTHON_VERSION\u001b[39;49;00m.tgz && \u001b[36mcd\u001b[39;49;00m Python-\u001b[31m$PYTHON_VERSION\u001b[39;49;00m && \u001b[33m\\\u001b[39;49;00m\n",
      "        ./configure && make && make install && \u001b[33m\\\u001b[39;49;00m\n",
      "        apt-get update && apt-get install -y --no-install-recommends libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev && \u001b[33m\\\u001b[39;49;00m\n",
      "        make && make install && rm -rf ../Python-\u001b[31m$PYTHON_VERSION\u001b[39;49;00m* && \u001b[33m\\\u001b[39;49;00m\n",
      "        ln -s /usr/local/bin/pip3 /usr/bin/pip\n",
      "\n",
      "\u001b[37m# Upgrading pip and creating symbolic link for python3\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m \u001b[33m${\u001b[39;49;00m\u001b[31mPIP\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m --no-cache-dir install --upgrade pip\n",
      "\u001b[34mRUN\u001b[39;49;00m ln -s \u001b[34m$(\u001b[39;49;00mwhich \u001b[33m${\u001b[39;49;00m\u001b[31mPYTHON\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[34m)\u001b[39;49;00m /usr/local/bin/python\n",
      "\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /\u001b[39;49;00m\n",
      "\n",
      "COPY code/custom_framework_training-1.0.0.tar.gz /custom_framework_training-1.0.0.tar.gz\n",
      "\n",
      "\u001b[37m# Installing numpy, pandas, scikit-learn, scipy\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m \u001b[33m${\u001b[39;49;00m\u001b[31mPIP\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m install --no-cache --upgrade \u001b[33m\\\u001b[39;49;00m\n",
      "        \u001b[31mnumpy\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.14.5 \u001b[33m\\\u001b[39;49;00m\n",
      "        \u001b[31mpandas\u001b[39;49;00m==\u001b[34m0\u001b[39;49;00m.24.1 \u001b[33m\\\u001b[39;49;00m\n",
      "        scikit-learn==\u001b[34m0\u001b[39;49;00m.20.3 \u001b[33m\\\u001b[39;49;00m\n",
      "        \u001b[31mrequests\u001b[39;49;00m==\u001b[34m2\u001b[39;49;00m.21.0 \u001b[33m\\\u001b[39;49;00m\n",
      "        \u001b[31mscipy\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.2.1 \u001b[33m\\\u001b[39;49;00m\n",
      "        /custom_framework_training-1.0.0.tar.gz && \u001b[33m\\\u001b[39;49;00m\n",
      "    rm /custom_framework_training-1.0.0.tar.gz\n",
      "\n",
      "\u001b[37m# Setting some environment variables.\u001b[39;49;00m\n",
      "\u001b[34mENV\u001b[39;49;00m\u001b[33m PYTHONDONTWRITEBYTECODE=1 \\\u001b[39;49;00m\n",
      "    \u001b[31mPYTHONUNBUFFERED\u001b[39;49;00m=\u001b[34m1\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\n",
      "    \u001b[31mLD_LIBRARY_PATH\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mLD_LIBRARY_PATH\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m:/usr/local/lib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\n",
      "    \u001b[31mPYTHONIOENCODING\u001b[39;49;00m=UTF-8 \u001b[33m\\\u001b[39;49;00m\n",
      "    \u001b[31mLANG\u001b[39;49;00m=C.UTF-8 \u001b[33m\\\u001b[39;49;00m\n",
      "    \u001b[31mLC_ALL\u001b[39;49;00m=C.UTF-8\n",
      "\n",
      "\u001b[34mENV\u001b[39;49;00m\u001b[33m SAGEMAKER_TRAINING_MODULE custom_framework_training.training:main\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "! pygmentize ../docker/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At high-level the Dockerfile specifies the following operations for building this container:\n",
    "<ul>\n",
    "    <li>Start from Ubuntu 16.04</li>\n",
    "    <li>Define some variables to be used at build time to install Python 3</li>\n",
    "    <li>Some handful libraries are installed with apt-get</li>\n",
    "    <li>We then install Python 3 and create a symbolic link</li>\n",
    "    <li>We copy a .tar.gz package named <strong>custom_framework_training-1.0.0.tar.gz</strong> in the WORKDIR</li>\n",
    "    <li>We then install some Python libraries like numpy, pandas, ScikitLearn <strong>and the package we copied at the previous step</strong></li>\n",
    "    <li>We set e few environment variables, including PYTHONUNBUFFERED which is used to avoid buffering Python standard output (useful for logging)</li>\n",
    "    <li>Finally, we set the value of the environment variable <strong>SAGEMAKER_TRAINING_MODULE</strong> to the training packaged we installed</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training module</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the Dockerfile above, you might be askiong yourself what the <strong>custom_framework_training-1.0.0.tar.gz</strong> package is.\n",
    "When building a framework container, sagemaker-containers expects that you include in the container a training module that will be responsibile of invoking a user-provided module or script.\n",
    "\n",
    "Our training module is part of a Python package - that you can find in the folder ../package/ - distributed as a .tar.gz by the Python setuptools library (https://setuptools.readthedocs.io/en/latest/).\n",
    "\n",
    "Setuptools uses a setup.py file to build the package. Following is the content of this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m absolute_import\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mglob\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m glob\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mos.path\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m basename\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mos.path\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m splitext\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msetuptools\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m find_packages, setup\n",
      "\n",
      "setup(\n",
      "    name=\u001b[33m'\u001b[39;49;00m\u001b[33mcustom_framework_training\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "    version=\u001b[33m'\u001b[39;49;00m\u001b[33m1.0.0\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "    description=\u001b[33m'\u001b[39;49;00m\u001b[33mCustom framework container training package.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "    keywords=\u001b[33m\"\u001b[39;49;00m\u001b[33mcustom framework contaier training package SageMaker\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "\n",
      "    packages=find_packages(where=\u001b[33m'\u001b[39;49;00m\u001b[33msrc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m),\n",
      "    package_dir={\u001b[33m'\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33msrc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\n",
      "    py_modules=[splitext(basename(path))[\u001b[34m0\u001b[39;49;00m] \u001b[34mfor\u001b[39;49;00m path \u001b[35min\u001b[39;49;00m glob(\u001b[33m'\u001b[39;49;00m\u001b[33msrc/*.py\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)],\n",
      "\n",
      "    author=\u001b[33m'\u001b[39;49;00m\u001b[33mGiuseppe A. Porcelli\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "    author_email=\u001b[33m'\u001b[39;49;00m\u001b[33mgiu.porcelli@gmail.com\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "    license=\u001b[33m'\u001b[39;49;00m\u001b[33mApache License 2.0\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "    \n",
      "    install_requires=[\u001b[33m'\u001b[39;49;00m\u001b[33msagemaker-containers==2.5.10\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ../package/setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This build script looks at the packages under the local src/ path and specifies the dependency on sagemaker-containers. The training module contains the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m absolute_import\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_containers.beta.framework\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mframework\u001b[39;49;00m\n",
      "\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(training_environment):\n",
      "    logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mInvoking user training script.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[37m# Execute user script as module.\u001b[39;49;00m\n",
      "    framework.modules.run_module(training_environment.module_dir, training_environment.to_cmd_args(),\n",
      "                                 training_environment.to_env_vars(), training_environment.module_name)\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\n",
      "    train(framework.training_env())\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ../package/src/custom_framework_training/training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is that we will use the <strong>run_module()</strong> function of the sagemaker-containers library to execute the user-provided training script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Build and push the container</h3>\n",
    "We are now ready to build this container and push it to Amazon ECR. This task is executed using a shell script stored in the ../script/ folder. Let's take a look at this script and then execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mACCOUNT_ID\u001b[39;49;00m=\u001b[31m$1\u001b[39;49;00m\n",
      "\u001b[31mREGION\u001b[39;49;00m=\u001b[31m$2\u001b[39;49;00m\n",
      "\u001b[31mREPO_NAME\u001b[39;49;00m=\u001b[31m$3\u001b[39;49;00m\n",
      "\n",
      "\u001b[36mcd\u001b[39;49;00m ../package/ && python setup.py sdist && cp dist/custom_framework_training-1.0.0.tar.gz ../docker/code/\n",
      "\n",
      "docker build -f ../docker/Dockerfile -t \u001b[31m$REPO_NAME\u001b[39;49;00m ../docker\n",
      "\n",
      "docker tag \u001b[31m$REPO_NAME\u001b[39;49;00m \u001b[31m$ACCOUNT_ID\u001b[39;49;00m.dkr.ecr.\u001b[31m$REGION\u001b[39;49;00m.amazonaws.com/\u001b[31m$REPO_NAME\u001b[39;49;00m:latest\n",
      "\n",
      "\u001b[34m$(\u001b[39;49;00maws ecr get-login --no-include-email --registry-ids \u001b[31m$ACCOUNT_ID\u001b[39;49;00m\u001b[34m)\u001b[39;49;00m\n",
      "\n",
      "aws ecr describe-repositories --repository-names \u001b[31m$REPO_NAME\u001b[39;49;00m || aws ecr create-repository --repository-name \u001b[31m$REPO_NAME\u001b[39;49;00m\n",
      "\n",
      "docker push \u001b[31m$ACCOUNT_ID\u001b[39;49;00m.dkr.ecr.\u001b[31m$REGION\u001b[39;49;00m.amazonaws.com/\u001b[31m$REPO_NAME\u001b[39;49;00m:latest\n"
     ]
    }
   ],
   "source": [
    "! pygmentize ../scripts/build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>--------------------------------------------------------------------------------------------------------------------</h3>\n",
    "First, the script runs the <strong>setup.py</strong> to create the training package, which is copied under <strong>../docker/code/</strong>.\n",
    "\n",
    "Then it builds the Docker container, creates the repository if it does not exist, and finally pushes the container to the ECR repository. The build task requires a few minutes to be executed the first time, then Docker caches build outputs to be reused for the subsequent build operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing src/custom_framework_training.egg-info/PKG-INFO\n",
      "writing dependency_links to src/custom_framework_training.egg-info/dependency_links.txt\n",
      "writing requirements to src/custom_framework_training.egg-info/requires.txt\n",
      "writing top-level names to src/custom_framework_training.egg-info/top_level.txt\n",
      "reading manifest file 'src/custom_framework_training.egg-info/SOURCES.txt'\n",
      "writing manifest file 'src/custom_framework_training.egg-info/SOURCES.txt'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "creating custom_framework_training-1.0.0\n",
      "creating custom_framework_training-1.0.0/src\n",
      "creating custom_framework_training-1.0.0/src/custom_framework_training\n",
      "creating custom_framework_training-1.0.0/src/custom_framework_training.egg-info\n",
      "copying files to custom_framework_training-1.0.0...\n",
      "copying setup.py -> custom_framework_training-1.0.0\n",
      "copying src/custom_framework_training/__init__.py -> custom_framework_training-1.0.0/src/custom_framework_training\n",
      "copying src/custom_framework_training/training.py -> custom_framework_training-1.0.0/src/custom_framework_training\n",
      "copying src/custom_framework_training.egg-info/PKG-INFO -> custom_framework_training-1.0.0/src/custom_framework_training.egg-info\n",
      "copying src/custom_framework_training.egg-info/SOURCES.txt -> custom_framework_training-1.0.0/src/custom_framework_training.egg-info\n",
      "copying src/custom_framework_training.egg-info/dependency_links.txt -> custom_framework_training-1.0.0/src/custom_framework_training.egg-info\n",
      "copying src/custom_framework_training.egg-info/requires.txt -> custom_framework_training-1.0.0/src/custom_framework_training.egg-info\n",
      "copying src/custom_framework_training.egg-info/top_level.txt -> custom_framework_training-1.0.0/src/custom_framework_training.egg-info\n",
      "Writing custom_framework_training-1.0.0/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'custom_framework_training-1.0.0' (and everything under it)\n",
      "Sending build context to Docker daemon  10.24kB\n",
      "Step 1/15 : FROM ubuntu:16.04\n",
      " ---> b9409899fe86\n",
      "Step 2/15 : LABEL maintainer=\"Amazon AI\"\n",
      " ---> Using cache\n",
      " ---> bab228941513\n",
      "Step 3/15 : ARG PYTHON=python3\n",
      " ---> Using cache\n",
      " ---> 753bc9f6b601\n",
      "Step 4/15 : ARG PYTHON_PIP=python3-pip\n",
      " ---> Using cache\n",
      " ---> 1d2afc099c45\n",
      "Step 5/15 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> 4637544f83e5\n",
      "Step 6/15 : ARG PYTHON_VERSION=3.6.6\n",
      " ---> Using cache\n",
      " ---> f16297f44d34\n",
      "Step 7/15 : RUN apt-get update && apt-get install -y --no-install-recommends software-properties-common &&     add-apt-repository ppa:deadsnakes/ppa -y &&     apt-get update && apt-get install -y --no-install-recommends         build-essential         ca-certificates         curl         wget         git         libopencv-dev         openssh-client         openssh-server         vim         zlib1g-dev &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> a2784e936cf9\n",
      "Step 8/15 : RUN wget https://www.python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tgz &&         tar -xvf Python-$PYTHON_VERSION.tgz && cd Python-$PYTHON_VERSION &&         ./configure && make && make install &&         apt-get update && apt-get install -y --no-install-recommends libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev &&         make && make install && rm -rf ../Python-$PYTHON_VERSION* &&         ln -s /usr/local/bin/pip3 /usr/bin/pip\n",
      " ---> Using cache\n",
      " ---> 13aa2435ce12\n",
      "Step 9/15 : RUN ${PIP} --no-cache-dir install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 98bb32ff97cc\n",
      "Step 10/15 : RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
      " ---> Using cache\n",
      " ---> 21f7e15904d2\n",
      "Step 11/15 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 15258349a3a5\n",
      "Step 12/15 : COPY code/custom_framework_training-1.0.0.tar.gz /custom_framework_training-1.0.0.tar.gz\n",
      " ---> 406111b4cf76\n",
      "Step 13/15 : RUN ${PIP} install --no-cache --upgrade         numpy==1.14.5         pandas==0.24.1         scikit-learn==0.20.3         requests==2.21.0         scipy==1.2.1         /custom_framework_training-1.0.0.tar.gz &&     rm /custom_framework_training-1.0.0.tar.gz\n",
      " ---> Running in 0c69d0eed6ed\n",
      "Processing /custom_framework_training-1.0.0.tar.gz\n",
      "Collecting numpy==1.14.5\n",
      "  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
      "Collecting pandas==0.24.1\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/de/a0d3defd8f338eaf53ef716e40ef6d6c277c35d50e09b586e170169cdf0d/pandas-0.24.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
      "Collecting scikit-learn==0.20.3\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/82/c0de5839d613b82bddd088599ac0bbfbbbcbd8ca470680658352d2c435bd/scikit_learn-0.20.3-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
      "Collecting requests==2.21.0\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
      "Collecting scipy==1.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n",
      "Collecting sagemaker-containers==2.5.10\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/eb/24ebf92db43b404e18b11e5bc2fff9086a81df2422234824b39566b74b6f/sagemaker_containers-2.5.10.tar.gz (49kB)\n",
      "Collecting python-dateutil>=2.5.0\n",
      "  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
      "Collecting pytz>=2011k\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading https://files.pythonhosted.org/packages/18/b0/8146a4f8dd402f60744fa380bc73ca47303cccf8b9190fd16a827281eac2/certifi-2019.9.11-py2.py3-none-any.whl (154kB)\n",
      "Collecting idna<2.9,>=2.5\n",
      "  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "Collecting urllib3<1.25,>=1.21.1\n",
      "  Downloading https://files.pythonhosted.org/packages/01/11/525b02e4acc0c747de8b6ccdab376331597c569c42ea66ab0a1dbd36eca2/urllib3-1.24.3-py2.py3-none-any.whl (118kB)\n",
      "Collecting chardet<3.1.0,>=3.0.2\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "Collecting boto3\n",
      "  Downloading https://files.pythonhosted.org/packages/0e/41/27fb3969a76240d4c42a8f64b9d5ae78c676bab38e980e03b1bbaef279bd/boto3-1.10.2-py2.py3-none-any.whl (128kB)\n",
      "Collecting six\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.6/site-packages (from sagemaker-containers==2.5.10->custom-framework-training==1.0.0) (19.3.1)\n",
      "Collecting flask==1.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/93/628509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flask-1.1.1-py2.py3-none-any.whl (94kB)\n",
      "Collecting gunicorn\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/da/b8dd8deb741bff556db53902d4706774c8e1e67265f69528c14c003644e6/gunicorn-19.9.0-py2.py3-none-any.whl (112kB)\n",
      "Collecting typing\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/2e/b480ee1b75e6d17d2993738670e75c1feeb9ff7f64452153cf018051cc92/typing-3.7.4.1-py3-none-any.whl\n",
      "Collecting retrying==1.3.3\n",
      "  Downloading https://files.pythonhosted.org/packages/44/ef/beae4b4ef80902f22e3af073397f079c96969c69b2c7d52a57ea9ae61c9d/retrying-1.3.3.tar.gz\n",
      "Collecting gevent\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/ca/5b5962361ed832847b6b2f9a2d0452c8c2f29a93baef850bb8ad067c7bf9/gevent-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n",
      "Collecting inotify_simple\n",
      "  Downloading https://files.pythonhosted.org/packages/55/80/4bbd33f6d6b305c509a90b37c1cf7255000344f513b36827ec2c17af5ad5/inotify_simple-1.1.8.tar.gz\n",
      "Collecting werkzeug==0.15.5\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/ab/d3bed6b92042622d24decc7aadc8877badf18aeca1571045840ad4956d3f/Werkzeug-0.15.5-py2.py3-none-any.whl (328kB)\n",
      "Collecting paramiko==2.4.2\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/ae/94e70d49044ccc234bfdba20114fa947d7ba6eb68a2e452d89b920e62227/paramiko-2.4.2-py2.py3-none-any.whl (193kB)\n",
      "Collecting psutil==5.4.8\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/58/0eae6e4466e5abf779d7e2b71fac7fba5f59e00ea36ddb3ed690419ccb0f/psutil-5.4.8.tar.gz (422kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting botocore<1.14.0,>=1.13.2\n",
      "  Downloading https://files.pythonhosted.org/packages/33/57/6cd269b6c243f5409fd60b480bf7b9c98a10fa9bb083af223189d7617db5/botocore-1.13.2-py2.py3-none-any.whl (5.3MB)\n",
      "Collecting s3transfer<0.3.0,>=0.2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Downloading https://files.pythonhosted.org/packages/65/e0/eb35e762802015cab1ccee04e8a277b03f1d8e53da3ec3106882ec42558b/Jinja2-2.10.3-py2.py3-none-any.whl (125kB)\n",
      "Collecting greenlet>=0.4.14; platform_python_implementation == \"CPython\"\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/45/142141aa47e01a5779f0fa5a53b81f8379ce8f2b1cd13df7d2f1d751ae42/greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl (41kB)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading https://files.pythonhosted.org/packages/27/15/2cd0a203f318c2240b42cd9dd13c931ddd61067809fee3479f44f086103e/PyNaCl-1.3.0-cp34-abi3-manylinux1_x86_64.whl (759kB)\n",
      "Collecting pyasn1>=0.1.7\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/71/8f0d444e3a74e5640a3d5d967c1c6b015da9c655f35b2d308a55d907a517/pyasn1-0.4.7-py2.py3-none-any.whl (76kB)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading https://files.pythonhosted.org/packages/8b/1d/82826443777dd4a624e38a08957b975e75df859b381ae302cfd7a30783ed/bcrypt-3.1.7-cp34-abi3-manylinux1_x86_64.whl (56kB)\n",
      "Collecting cryptography>=1.5\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/9a/7cece52c46546e214e10811b36b2da52ce1ea7fa203203a629b8dfadad53/cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3MB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/5f/23e0023be6bb885d00ffbefad2942bc51a620328ee910f64abe5a8d18dd1/MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting cffi>=1.4.1\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/15/d6bd2c322da944ba74ca545dd5e4af6e1e72339cbbc738e6877e349cdfbe/cffi-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (392kB)\n",
      "Collecting pycparser\n",
      "  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz (158kB)\n",
      "Installing collected packages: numpy, six, python-dateutil, pytz, pandas, scipy, scikit-learn, certifi, idna, urllib3, chardet, requests, jmespath, docutils, botocore, s3transfer, boto3, click, itsdangerous, werkzeug, MarkupSafe, Jinja2, flask, gunicorn, typing, retrying, greenlet, gevent, inotify-simple, pycparser, cffi, pynacl, pyasn1, bcrypt, cryptography, paramiko, psutil, sagemaker-containers, custom-framework-training\n",
      "    Running setup.py install for retrying: started\n",
      "    Running setup.py install for retrying: finished with status 'done'\n",
      "    Running setup.py install for inotify-simple: started\n",
      "    Running setup.py install for inotify-simple: finished with status 'done'\n",
      "    Running setup.py install for pycparser: started\n",
      "    Running setup.py install for pycparser: finished with status 'done'\n",
      "    Running setup.py install for psutil: started\n",
      "    Running setup.py install for psutil: finished with status 'done'\n",
      "    Running setup.py install for sagemaker-containers: started\n",
      "    Running setup.py install for sagemaker-containers: finished with status 'done'\n",
      "    Running setup.py install for custom-framework-training: started\n",
      "    Running setup.py install for custom-framework-training: finished with status 'done'\n",
      "Successfully installed Jinja2-2.10.3 MarkupSafe-1.1.1 bcrypt-3.1.7 boto3-1.10.2 botocore-1.13.2 certifi-2019.9.11 cffi-1.13.1 chardet-3.0.4 click-7.0 cryptography-2.8 custom-framework-training-1.0.0 docutils-0.15.2 flask-1.1.1 gevent-1.4.0 greenlet-0.4.15 gunicorn-19.9.0 idna-2.8 inotify-simple-1.1.8 itsdangerous-1.1.0 jmespath-0.9.4 numpy-1.14.5 pandas-0.24.1 paramiko-2.4.2 psutil-5.4.8 pyasn1-0.4.7 pycparser-2.19 pynacl-1.3.0 python-dateutil-2.8.0 pytz-2019.3 requests-2.21.0 retrying-1.3.3 s3transfer-0.2.1 sagemaker-containers-2.5.10 scikit-learn-0.20.3 scipy-1.2.1 six-1.12.0 typing-3.7.4.1 urllib3-1.24.3 werkzeug-0.15.5\n",
      "Removing intermediate container 0c69d0eed6ed\n",
      " ---> 40e87c70e913\n",
      "Step 14/15 : ENV PYTHONDONTWRITEBYTECODE=1     PYTHONUNBUFFERED=1     LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"     PYTHONIOENCODING=UTF-8     LANG=C.UTF-8     LC_ALL=C.UTF-8\n",
      " ---> Running in 4168c6409f93\n",
      "Removing intermediate container 4168c6409f93\n",
      " ---> a60532aa50f7\n",
      "Step 15/15 : ENV SAGEMAKER_TRAINING_MODULE custom_framework_training.training:main\n",
      " ---> Running in 63527f1b387e\n",
      "Removing intermediate container 63527f1b387e\n",
      " ---> 972b857b6df4\n",
      "Successfully built 972b857b6df4\n",
      "Successfully tagged gianpo-ecr/framework-container:latest\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryArn\": \"arn:aws:ecr:eu-west-1:825935527263:repository/gianpo-ecr/framework-container\",\n",
      "            \"registryId\": \"825935527263\",\n",
      "            \"repositoryName\": \"gianpo-ecr/framework-container\",\n",
      "            \"repositoryUri\": \"825935527263.dkr.ecr.eu-west-1.amazonaws.com/gianpo-ecr/framework-container\",\n",
      "            \"createdAt\": 1571840259.0,\n",
      "            \"imageTagMutability\": \"MUTABLE\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "The push refers to repository [825935527263.dkr.ecr.eu-west-1.amazonaws.com/gianpo-ecr/framework-container]\n",
      "\n",
      "\u001b[1B55ba8ed5: Preparing \n",
      "\u001b[1Bd245d107: Preparing \n",
      "\u001b[1B36e921fa: Preparing \n",
      "\u001b[1B6df72fd8: Preparing \n",
      "\u001b[1Bf4414656: Preparing \n",
      "\u001b[1B19f30d7a: Preparing \n",
      "\u001b[1B13a20bf2: Preparing \n",
      "\u001b[1Bcdf4e497: Preparing \n",
      "\u001b[1B3f9454c0: Preparing \n",
      "\u001b[10B5ba8ed5: Pushed     312MB/304.6MB\u001b[5A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[KPushing  545.3kB/304.6MB\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[KPushing  254.2MB/304.6MB\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[Klatest: digest: sha256:68fa9679bc4cbc41cb6bf7895e4528486b6023f687ee385c295abf185840abec size: 2413\n"
     ]
    }
   ],
   "source": [
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training with Amazon SageMaker</h3>\n",
    "\n",
    "Once we have correctly pushed our container to Amazon ECR, we are ready to start training with Amazon SageMaker, which requires the ECR path to the Docker container used for training as parameter for starting a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825935527263.dkr.ecr.eu-west-1.amazonaws.com/gianpo-ecr/framework-container:latest\n"
     ]
    }
   ],
   "source": [
    "container_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the purpose of this example is explaining how to build custom framework containers, we are not going to train a real model. The script that will be executed does not define a specific training logic; it just outputs the configurations injected by SageMaker and implements a dummy training loop. Training data is also dummy. Let's analyze the script first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m absolute_import\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mutils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m save_model_artifacts, print_files_in_path\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(hp1, hp2, hp3, train_channel, validation_channel):\n",
      "\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mList of files in train channel: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    print_files_in_path(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mList of files in validation channel: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    print_files_in_path(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    \u001b[37m# Dummy net.\u001b[39;49;00m\n",
      "    net = \u001b[36mNone\u001b[39;49;00m\n",
      "        \n",
      "    \u001b[37m# Run training loop.\u001b[39;49;00m\n",
      "    epochs = \u001b[34m1\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m x \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(epochs):\n",
      "        \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mRunning epoch {0}...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(x))\n",
      "\n",
      "        time.sleep(\u001b[34m30\u001b[39;49;00m)\n",
      "\n",
      "        \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCompleted epoch {0}.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(x))\n",
      "        \n",
      "    \u001b[37m# At the end of the training loop, we have to save model artifacts.\u001b[39;49;00m\n",
      "    model_dir = os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    save_model_artifacts(model_dir + \u001b[33m'\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, net)\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "\n",
      "    parser = argparse.ArgumentParser()\n",
      "    \n",
      "    \u001b[37m# sagemaker-containers passes hyperparameters as arguments\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hp1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hp2\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m50\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hp3\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.1\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[37m# This is a way to pass additional arguments when running as a script\u001b[39;49;00m\n",
      "    \u001b[37m# and use sagemaker-containers defaults to set their values when not specified.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    args = parser.parse_args()\n",
      "    \n",
      "    train(args.hp1, args.hp2, args.hp3, args.train, args.validation)\n"
     ]
    }
   ],
   "source": [
    "! pygmentize source_dir/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can realize that the training code has been implemented as a standard Python script, that will be invoked as a module by the framework container code, passing hyperparameters as arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we upload some dummy data to Amazon S3, in order to define our S3-based training channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-west-1-825935527263/framework-container/train/dummy.csv\n",
      "s3://sagemaker-eu-west-1-825935527263/framework-container/val/dummy.csv\n"
     ]
    }
   ],
   "source": [
    "! echo \"val1, val2, val3\" > dummy.csv\n",
    "print(sagemaker_session.upload_data('dummy.csv', bucket, prefix + '/train'))\n",
    "print(sagemaker_session.upload_data('dummy.csv', bucket, prefix + '/val'))\n",
    "! rm dummy.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before, framework containers enable dynamically running user-provided code by either loading it from Amazon S3 or from a GitHub repository. In this case we are going to leverage on Amazon S3, so we need to:\n",
    "<ul>\n",
    "    <li>Package the <strong>source_dir</strong> folder in a tar.gz archive</li>\n",
    "    <li>Upload the archive to Amazon S3</li>\n",
    "    <li>Specify the path to the archive in Amazon S3 as one of the parameters of the training job</li>\n",
    "</ul>\n",
    "\n",
    "<strong>Note:</strong> these steps are executed automatically by the Amazon SageMaker Python SDK when using framework estimators for MXNet, Tensorflow, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sourcedir.tar.gz'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "def create_tar_file(source_files, target=None):\n",
    "    if target:\n",
    "        filename = target\n",
    "    else:\n",
    "        _, filename = tempfile.mkstemp()\n",
    "\n",
    "    with tarfile.open(filename, mode=\"w:gz\") as t:\n",
    "        for sf in source_files:\n",
    "            # Add all files from the directory into the root of the directory structure of the tar\n",
    "            t.add(sf, arcname=os.path.basename(sf))\n",
    "    return filename\n",
    "\n",
    "create_tar_file([\"source_dir/train.py\", \"source_dir/utils.py\"], \"sourcedir.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-west-1-825935527263/framework-container/code/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "sources = sagemaker_session.upload_data('sourcedir.tar.gz', bucket, prefix + '/code')\n",
    "print(sources)\n",
    "! rm sourcedir.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When starting the training job, we need to let the sagemaker-containers library know where the sources are stored in Amazon S3 and what is the module to be invoked. These parameters are specified through the following reserved hyperparameters (these reserved hyperparameters are injected automatically when using framework estimators of the Amazon SageMaker Python SDK):\n",
    "<ul>\n",
    "    <li>sagemaker_program</li>\n",
    "    <li>sagemaker_submit_directory</li>\n",
    "</ul>\n",
    "\n",
    "Finally, we can execute the training job by calling the fit() method of the generic Estimator object defined in the Amazon SageMaker Python SDK (https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/estimator.py). This corresponds to calling the CreateTrainingJob() API (https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTrainingJob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 11:50:39 Starting - Starting the training job...\n",
      "2019-10-25 11:50:41 Starting - Launching requested ML instances......\n",
      "2019-10-25 11:52:03 Starting - Preparing the instances for training......\n",
      "2019-10-25 11:53:00 Downloading - Downloading input data\n",
      "2019-10-25 11:53:00 Training - Downloading the training image....\u001b[31m2019-10-25 11:53:42,081 sagemaker-containers INFO     Imported framework custom_framework_training.training\u001b[0m\n",
      "\u001b[31m2019-10-25 11:53:42,084 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-10-25 11:53:42,096 custom_framework_training.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-10-25 11:53:42,368 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-10-25 11:53:42,368 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-10-25 11:53:42,368 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-10-25 11:53:42,368 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/local/bin/python3.6 -m pip install . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mInstalling collected packages: train\n",
      "    Running setup.py install for train: started\n",
      "    Running setup.py install for train: finished with status 'done'\u001b[0m\n",
      "\u001b[31mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[31m2019-10-25 11:53:43,912 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-10-25 11:53:43,924 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"custom_framework_training.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hp1\": \"value1\",\n",
      "        \"hp3\": 0.001,\n",
      "        \"hp2\": 300\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"framework-container-2019-10-25-11-50-39-101\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-825935527263/framework-container-2019-10-25-10-20-53-083/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=custom_framework_training.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-eu-west-1-825935527263/framework-container-2019-10-25-10-20-53-083/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"custom_framework_training.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"framework-container-2019-10-25-11-50-39-101\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-825935527263/framework-container-2019-10-25-10-20-53-083/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--hp1\",\"value1\",\"--hp2\",\"300\",\"--hp3\",\"0.001\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HP_HP1=value1\u001b[0m\n",
      "\u001b[31mSM_HP_HP3=0.001\u001b[0m\n",
      "\u001b[31mSM_HP_HP2=300\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/local/bin/python3.6 -m train --hp1 value1 --hp2 300 --hp3 0.001\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mList of files in train channel: \u001b[0m\n",
      "\u001b[31m/opt/ml/input/data/train/dummy.csv\n",
      "\u001b[0m\n",
      "\u001b[31mList of files in validation channel: \u001b[0m\n",
      "\u001b[31m/opt/ml/input/data/validation/dummy.csv\n",
      "\u001b[0m\n",
      "\u001b[31mRunning epoch 0...\u001b[0m\n",
      "\n",
      "2019-10-25 11:53:41 Training - Training image download completed. Training in progress.\u001b[31mCompleted epoch 0.\n",
      "\u001b[0m\n",
      "\u001b[31mRunning epoch 1...\u001b[0m\n",
      "\u001b[31mCompleted epoch 1.\n",
      "\u001b[0m\n",
      "\u001b[31mRunning epoch 2...\u001b[0m\n",
      "\u001b[31mCompleted epoch 2.\n",
      "\u001b[0m\n",
      "\u001b[31mRunning epoch 3...\u001b[0m\n",
      "\u001b[31mCompleted epoch 3.\n",
      "\u001b[0m\n",
      "\u001b[31mRunning epoch 4...\u001b[0m\n",
      "\u001b[31mCompleted epoch 4.\u001b[0m\n",
      "\u001b[31m2019-10-25 11:56:14,092 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-10-25 11:56:23 Uploading - Uploading generated training model\n",
      "2019-10-25 11:56:23 Completed - Training job completed\n",
      "Training seconds: 217\n",
      "Billable seconds: 217\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "# JSON encode hyperparameters to avoid showing some info messages raised by the sagemaker-containers library.\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters({\n",
    "    \"sagemaker_program\": \"train\",\n",
    "    \"sagemaker_submit_directory\": sources,\n",
    "    \"hp1\": \"value1\",\n",
    "    \"hp2\": 300,\n",
    "    \"hp3\": 0.001})\n",
    "\n",
    "est = sagemaker.estimator.Estimator(container_image_uri,\n",
    "                                    role,\n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m5.xlarge',\n",
    "                                    base_job_name=prefix,\n",
    "                                    hyperparameters=hyperparameters)\n",
    "\n",
    "train_config = sagemaker.session.s3_input('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.session.s3_input('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "\n",
    "est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training with a custom SDK framework estimator</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have seen, in the previous steps we had to upload our code to Amazon S3 and then inject reserved hyperparameters to execute training. In order to facilitate this task, you can also try defining a custom framework estimator using the Amazon SageMaker Python SDK and run training with that class, which will take care of managing these tasks.\n",
    "\n",
    "Moreover, this approach will allow you to leverage on local mode training (https://sagemaker.readthedocs.io/en/stable/overview.html#id6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpp6sp8hdd_algo-1-fptd8_1 ... \n",
      "\u001b[1BAttaching to tmpp6sp8hdd_algo-1-fptd8_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m 2019-10-25 10:29:09,048 sagemaker-containers INFO     Imported framework custom_framework_training.training\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m 2019-10-25 10:29:09,051 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m 2019-10-25 10:29:09,063 custom_framework_training.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m 2019-10-25 10:29:09,170 sagemaker-containers INFO     Module train does not provide a setup.py. \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m 2019-10-25 10:29:09,170 sagemaker-containers INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m 2019-10-25 10:29:09,170 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m 2019-10-25 10:29:09,170 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m /usr/local/bin/python3.6 -m pip install . \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Installing collected packages: train\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     Running setup.py install for train ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \u001b[?25hSuccessfully installed train-1.0.0\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m 2019-10-25 10:29:10,283 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m 2019-10-25 10:29:10,296 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"current_host\": \"algo-1-fptd8\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"framework_module\": \"custom_framework_training.training:main\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m         \"algo-1-fptd8\"\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m         \"hp1\": \"value1\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m         \"hp2\": \"300\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m         \"hp3\": \"0.001\"\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m             \"ContentType\": \"text/csv\"\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m         \"validation\": {\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m             \"ContentType\": \"text/csv\"\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"job_name\": \"framework-container-2019-10-25-10-29-06-056\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"master_hostname\": \"algo-1-fptd8\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-eu-west-1-825935527263/framework-container-2019-10-25-10-29-06-056/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m         \"current_host\": \"algo-1-fptd8\",\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m             \"algo-1-fptd8\"\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_HOSTS=[\"algo-1-fptd8\"]\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_HPS={\"hp1\":\"value1\",\"hp2\":\"300\",\"hp3\":\"0.001\"}\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-fptd8\",\"hosts\":[\"algo-1-fptd8\"]}\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_CURRENT_HOST=algo-1-fptd8\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_FRAMEWORK_MODULE=custom_framework_training.training:main\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-eu-west-1-825935527263/framework-container-2019-10-25-10-29-06-056/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-fptd8\",\"framework_module\":\"custom_framework_training.training:main\",\"hosts\":[\"algo-1-fptd8\"],\"hyperparameters\":{\"hp1\":\"value1\",\"hp2\":\"300\",\"hp3\":\"0.001\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"framework-container-2019-10-25-10-29-06-056\",\"log_level\":20,\"master_hostname\":\"algo-1-fptd8\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-825935527263/framework-container-2019-10-25-10-29-06-056/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-fptd8\",\"hosts\":[\"algo-1-fptd8\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_USER_ARGS=[\"--hp1\",\"value1\",\"--hp2\",\"300\",\"--hp3\",\"0.001\"]\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_HP_HP1=value1\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_HP_HP2=300\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m SM_HP_HP3=0.001\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m PYTHONPATH=/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m /usr/local/bin/python3.6 -m train --hp1 value1 --hp2 300 --hp3 0.001\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m List of files in train channel: \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m /opt/ml/input/data/train/dummy.csv\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m List of files in validation channel: \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m /opt/ml/input/data/validation/dummy.csv\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Running epoch 0...\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Completed epoch 0.\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Running epoch 1...\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Completed epoch 1.\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Running epoch 2...\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Completed epoch 2.\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Running epoch 3...\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Completed epoch 3.\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m \n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Running epoch 4...\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m Completed epoch 4.\n",
      "\u001b[36malgo-1-fptd8_1  |\u001b[0m 2019-10-25 10:31:40,403 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmpp6sp8hdd_algo-1-fptd8_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Framework\n",
    "\n",
    "class CustomFramework(Framework):\n",
    "    def __init__(\n",
    "        self,\n",
    "        entry_point,\n",
    "        source_dir=None,\n",
    "        hyperparameters=None,\n",
    "        py_version=\"py2\",\n",
    "        framework_version=None,\n",
    "        image_name=None,\n",
    "        distributions=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(CustomFramework, self).__init__(\n",
    "            entry_point, source_dir, hyperparameters, image_name=image_name, **kwargs\n",
    "        )\n",
    "    \n",
    "    def _configure_distribution(self, distributions):\n",
    "        return\n",
    "    \n",
    "    def create_model(\n",
    "        self,\n",
    "        model_server_workers=None,\n",
    "        role=None,\n",
    "        vpc_config_override=None,\n",
    "        entry_point=None,\n",
    "        source_dir=None,\n",
    "        dependencies=None,\n",
    "        image_name=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return None\n",
    "        \n",
    "import sagemaker\n",
    "\n",
    "est = CustomFramework(image_name=container_image_uri,\n",
    "                      role=role,\n",
    "                      entry_point='train.py',\n",
    "                      source_dir='source_dir/',\n",
    "                      train_instance_count=1, \n",
    "                      train_instance_type='local',\n",
    "                      base_job_name=prefix,\n",
    "                      hyperparameters={\n",
    "                          \"hp1\": \"value1\",\n",
    "                          \"hp2\": \"300\",\n",
    "                          \"hp3\": \"0.001\"\n",
    "                      })\n",
    "\n",
    "train_config = sagemaker.session.s3_input('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.session.s3_input('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "\n",
    "est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
